version: '2.1'
services:

    postgres:
        image: postgres:9.6
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow

    webserver:
        image: custom-docker-airflow-spark
        build:
            context: ..
            dockerfile: ../Dockerfile.airflow_spark
        restart: always
        depends_on:
            - postgres
        environment:
            - LOAD_EX=n
            - EXECUTOR=Local
        volumes:
            - ../dags:/usr/local/airflow/dags
            - ../plugins:/usr/local/airflow/plugins
            - ./logs:/usr/local/airflow/logs
            - ../../requirements.txt:/requirements.txt
            - ./spark:/usr/local/airflow/spark
        ports:
            - "8080:8080"
        command: webserver
        healthcheck:
            test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
            interval: 30s
            timeout: 30s
            retries: 3

    db:
        image: postgres:10.10-alpine
        restart: always
        environment:
            POSTGRES_DB: 'postgres'
            POSTGRES_USER: 'postgres'
            POSTGRES_PASSWORD: 'postgres'
        ports:
            - "5432:5432"
        volumes:
           # - /var/lib/postgresql/10/main:/var/lib/postgresql/data
            - ./script/init.sql:/docker-entrypoint-initdb.d/init.sql
            - ../../data:/data

    spark-master:
        image: bde2020/spark-master:2.4.4-hadoop2.7
        container_name: spark-master
        ports:
            - "8088:8080"
            - "7077:7077"
        environment:
            - INIT_DAEMON_STEP=setup_spark
        volumes:
            - ./spark:/root/spark

    spark-worker-1:
        image: bde2020/spark-worker:2.4.4-hadoop2.7
        container_name: spark-worker-1
        depends_on:
            - spark-master
        ports:
            - "8081:8081"
        environment:
            - "SPARK_MASTER=spark://spark-master:7077"
        volumes:
            - ./spark:/root/spark